<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Writing Performance-Optimized C++ Code: Best Practices</title>
    <link rel="stylesheet" href="../css/styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <style>
        :root {
            --primary-color: #007acc;
            --secondary-color: #4caf50;
            --accent-color: #ff6b35;
            --bg-dark: #1e1e1e;
            --bg-light: #f8f9fa;
            --text-light: #333;
            --text-dark: #d4d4d4;
            --border-color: #e0e0e0;
            --success-color: #4caf50;
            --warning-color: #ff9800;
            --error-color: #f44336;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: white;
            border-radius: 10px;
            margin-top: 20px;
            margin-bottom: 20px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            box-sizing: border-box;
            overflow-x: hidden;
        }

        .content-wrapper {
            max-width: 100%;
            margin: 0 auto;
            box-sizing: border-box;
            overflow: hidden;
        }

        section {
            margin-bottom: 40px;
            padding: 0 10px;
            box-sizing: border-box;
            overflow: hidden;
        }

        section h2 {
            margin-bottom: 25px;
            padding-bottom: 10px;
            border-bottom: 2px solid var(--primary-color);
            color: var(--primary-color);
            font-weight: 600;
        }

        .back-button {
            position: fixed;
            top: 20px;
            left: 20px;
            background: var(--primary-color);
            color: white;
            padding: 10px 15px;
            border-radius: 25px;
            text-decoration: none;
            font-weight: bold;
            transition: all 0.3s ease;
            z-index: 1000;
            box-shadow: 0 4px 15px rgba(255, 107, 53, 0.3);
        }

        .back-button:hover {
            background: #e55a2b;
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(255, 107, 53, 0.4);
        }

        .hero-section {
            text-align: center;
            padding: 40px 0;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 10px;
            margin-bottom: 30px;
        }

        .hero-section h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 700;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .hero-section .subtitle {
            font-size: 1.2em;
            opacity: 0.9;
            margin-bottom: 20px;
        }

        .meta-info {
            display: flex;
            justify-content: center;
            gap: 20px;
            font-size: 0.9em;
            opacity: 0.8;
        }

        .section-nav {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 12px;
            margin-bottom: 35px;
            border-left: 5px solid var(--primary-color);
            box-shadow: 0 3px 15px rgba(0,0,0,0.05);
        }

        .section-nav h3 {
            margin-top: 0;
            margin-bottom: 20px;
            color: var(--primary-color);
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .nav-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }

        .nav-item {
            background: white;
            padding: 20px;
            border-radius: 10px;
            border: 1px solid #e0e0e0;
            transition: all 0.3s ease;
            cursor: pointer;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        }

        .nav-item:hover {
            transform: translateY(-3px);
            box-shadow: 0 6px 20px rgba(0,0,0,0.12);
            border-color: var(--primary-color);
        }

        .nav-item h4 {
            margin: 0 0 10px 0;
            color: var(--primary-color);
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .nav-item p {
            margin: 0;
            font-size: 0.95em;
            color: #666;
            line-height: 1.5;
        }

        .best-practice {
            background: #f8f9fa;
            border-left: 5px solid var(--primary-color);
            padding: 25px;
            margin: 25px 0;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
            overflow: hidden;
            display: flex;
            flex-direction: column;
        }

        .best-practice h3 {
            color: var(--primary-color);
            margin-top: 0;
            margin-bottom: 15px;
            font-weight: 600;
        }

        .best-practice p {
            margin-bottom: 20px;
            line-height: 1.7;
        }

        .code-example {
            background: #1e1e1e;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            overflow-x: auto;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }

        .code-example pre {
            margin: 0;
            color: #d4d4d4;
            font-size: 14px;
            line-height: 1.5;
        }

        .comparison-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 25px;
            margin: 25px 0;
            align-items: start;
            width: 100%;
            box-sizing: border-box;
        }

        .comparison-card {
            padding: 25px;
            border-radius: 12px;
            border: 2px solid;
            height: 100%;
            display: flex;
            flex-direction: column;
            box-sizing: border-box;
            word-wrap: break-word;
            overflow: hidden;
        }

        .comparison-card h4 {
            margin-top: 0;
            margin-bottom: 15px;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .comparison-card .code-example {
            margin: 15px 0 0 0;
            flex-grow: 1;
            overflow: hidden;
        }

        .comparison-card .code-example pre {
            overflow-x: auto;
            overflow-y: hidden;
            max-width: 100%;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .good-practice {
            background: #e8f5e8;
            border-color: var(--success-color);
        }

        .bad-practice {
            background: #ffeaea;
            border-color: var(--error-color);
        }

        .good-practice h4 {
            color: var(--success-color);
            margin-top: 0;
        }

        .bad-practice h4 {
            color: var(--error-color);
            margin-top: 0;
        }

        .performance-tip {
            background: linear-gradient(135deg, #e3f2fd, #bbdefb);
            border: 1px solid #2196f3;
            border-radius: 12px;
            padding: 25px;
            margin: 25px 0;
            box-shadow: 0 3px 15px rgba(33, 150, 243, 0.1);
        }

        .performance-tip h4 {
            color: #1976d2;
            margin-top: 0;
            margin-bottom: 15px;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .performance-tip p, .performance-tip ul {
            margin-bottom: 10px;
            line-height: 1.7;
        }

        .benchmark-result {
            background: #fff3e0;
            border: 1px solid #ff9800;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 14px;
            line-height: 1.6;
            box-shadow: 0 2px 8px rgba(255, 152, 0, 0.1);
        }

        .advanced-section {
            background: linear-gradient(135deg, #e8f4fd, #f0f9ff);
            border: 2px solid #2196f3;
            border-radius: 15px;
            padding: 30px;
            margin: 30px 0;
            box-shadow: 0 5px 20px rgba(33, 150, 243, 0.1);
        }

        .advanced-section h3 {
            color: #1976d2;
            margin-top: 0;
            margin-bottom: 20px;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .technique-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 25px;
            margin: 25px 0;
            align-items: start;
        }

        .technique-card {
            background: white;
            border-radius: 12px;
            padding: 25px;
            border: 1px solid #e0e0e0;
            box-shadow: 0 3px 15px rgba(0,0,0,0.08);
            height: 100%;
            display: flex;
            flex-direction: column;
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }

        .technique-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 25px rgba(0,0,0,0.12);
        }

        .technique-card h5 {
            color: var(--primary-color);
            margin-top: 0;
            margin-bottom: 15px;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .technique-card p, .technique-card ul {
            margin-bottom: 10px;
            line-height: 1.6;
            flex-grow: 1;
        }

        .technique-card .code-example {
            margin: 15px 0 0 0;
            font-size: 12px;
        }

        .code-playground {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 12px;
            overflow: hidden;
            margin: 25px 0;
            box-shadow: 0 4px 15px rgba(0,0,0,0.08);
        }

        .code-header {
            background: linear-gradient(90deg, #2196f3, #21cbf3);
            padding: 15px 20px;
            color: white;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .code-title {
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 12px;
            font-size: 16px;
        }

        .code-actions {
            display: flex;
            gap: 12px;
        }

        .btn {
            padding: 10px 18px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.3s ease;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 6px;
        }

        .btn:hover {
            transform: translateY(-1px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.2);
        }

        .btn-primary {
            background: var(--success-color);
            color: white;
        }

        .btn-secondary {
            background: var(--warning-color);
            color: white;
        }

        .btn:hover {
            transform: translateY(-1px);
            box-shadow: 0 4px 10px rgba(0,0,0,0.2);
        }

        .interactive-demo {
            background: #fff8e1;
            border: 2px solid #ffb74d;
            border-radius: 15px;
            padding: 30px;
            margin: 30px 0;
            box-shadow: 0 3px 15px rgba(255, 183, 77, 0.1);
        }

        .interactive-demo h4 {
            color: #2196f3;
            margin-top: 0;
            margin-bottom: 15px;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .quick-tips {
            background: linear-gradient(135deg, #f0f8ff, #e6f3ff);
            border: 1px solid #2196f3;
            border-radius: 12px;
            padding: 30px;
            margin: 35px 0;
            box-shadow: 0 3px 15px rgba(33, 150, 243, 0.1);
        }

        .quick-tips h2 {
            margin-top: 0;
            margin-bottom: 25px;
            color: #1976d2;
            text-align: center;
            font-weight: 600;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
        }

        .quick-tips ul {
            columns: 2;
            column-gap: 40px;
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .quick-tips li {
            margin-bottom: 15px;
            padding: 12px 15px;
            background: white;
            border-radius: 8px;
            border-left: 4px solid var(--primary-color);
            break-inside: avoid;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
            line-height: 1.6;
        }

        .quick-tips li strong {
            color: var(--primary-color);
        }
        
        @media (max-width: 1024px) {
            .comparison-grid {
                gap: 20px;
            }
            
            .comparison-card {
                padding: 20px;
            }
            
            .comparison-card .code-example pre {
                font-size: 13px;
            }
        }

        @media (max-width: 768px) {
            .container {
                margin: 10px;
                padding: 15px;
            }
            
            .comparison-grid {
                grid-template-columns: 1fr;
                gap: 20px;
            }
            
            .technique-grid {
                grid-template-columns: 1fr;
                gap: 20px;
            }
            
            .nav-grid {
                grid-template-columns: 1fr;
                gap: 15px;
            }
            
            .quick-tips ul {
                columns: 1;
            }
            
            .hero-section h1 {
                font-size: 2em;
            }
            
            .hero-section .subtitle {
                font-size: 1.1em;
            }
            
            .meta-info {
                flex-direction: column;
                gap: 10px;
            }
            
            .code-header {
                flex-direction: column;
                gap: 15px;
                align-items: flex-start;
            }
            
            .code-actions {
                width: 100%;
                justify-content: center;
            }
            
            section {
                padding: 0 5px;
            }
            
            .best-practice,
            .advanced-section,
            .interactive-demo,
            .performance-tip {
                padding: 20px;
                margin: 20px 0;
            }
            
            .comparison-grid {
                grid-template-columns: 1fr;
                gap: 15px;
                margin: 15px 0;
            }
            
            .comparison-card,
            .technique-card {
                padding: 20px;
                margin-bottom: 15px;
            }
            
            .comparison-card .code-example pre,
            .technique-card .code-example pre {
                font-size: 12px;
                overflow-x: auto;
                white-space: pre;
                word-wrap: normal;
            }
        }
    </style>
</head>
<body>
    <header>
        <nav>
            <div class="nav-brand">
                <span class="avatar">DKY</span>
                <span class="brand-name">Deepak Kumar Yadav</span>
            </div>
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="../blog.html">My Blog</a></li>
            </ul>
            <button id="theme-toggle" aria-label="Toggle dark mode">🌙</button>
        </nav>
    </header>

    <div class="container">
        <div class="content-wrapper">
            <div class="hero-section">
            <h1><i class="fas fa-rocket"></i> Writing Performance-Optimized C++ Code</h1>
            <p class="subtitle">Essential techniques and best practices for high-performance C++ development</p>
            <div class="meta-info">
                <span><i class="fas fa-clock"></i> 15 min read</span>
                <span><i class="fas fa-code"></i> Advanced</span>
                <span><i class="fas fa-tags"></i> C++, Performance, Optimization</span>
            </div>
        </div>

        <div class="section-nav">
            <h3><i class="fas fa-map"></i> What You'll Learn</h3>
            <div class="nav-grid">
                <div class="nav-item">
                    <h4><i class="fas fa-brain"></i> Memory Optimization</h4>
                    <p>Stack vs heap allocation, memory pools, and smart pointers</p>
                </div>
                <div class="nav-item">
                    <h4><i class="fas fa-code"></i> Algorithm Design</h4>
                    <p>Container selection, loop optimization, and data structures</p>
                </div>
                <div class="nav-item">
                    <h4><i class="fas fa-microchip"></i> Compiler Optimization</h4>
                    <p>Move semantics, compiler flags, and optimization hints</p>
                </div>
                <div class="nav-item">
                    <h4><i class="fas fa-tachometer-alt"></i> Cache Optimization</h4>
                    <p>Cache-friendly design and memory access patterns</p>
                </div>
                <div class="nav-item">
                    <h4><i class="fas fa-chart-line"></i> Profiling Techniques</h4>
                    <p>Measurement tools and performance analysis</p>
                </div>
                <div class="nav-item">
                    <h4><i class="fas fa-tools"></i> Advanced Techniques</h4>
                    <p>SIMD, parallel algorithms, and low-level optimizations</p>
                </div>
            </div>
        </div>

        <section>
            <h2><i class="fas fa-bolt"></i> Introduction</h2>
            <p>C++ is renowned for its performance capabilities, but writing truly optimized code requires understanding both the language features and the underlying hardware. This comprehensive guide covers essential techniques for writing performance-optimized C++ code that can make the difference between slow and blazingly fast applications.</p>
            
            <div class="performance-tip">
                <h4><i class="fas fa-lightbulb"></i> Performance Philosophy</h4>
                <p>Performance optimization in C++ follows the <strong>80/20 rule</strong>: 80% of performance issues come from 20% of your code. The key is identifying those critical 20% sections and optimizing them effectively while maintaining code readability and maintainability.</p>
            </div>

            <div class="technique-grid">
                <div class="technique-card">
                    <h5><i class="fas fa-stopwatch"></i> Latency vs Throughput</h5>
                    <p><strong>Latency:</strong> Time to process a single request<br>
                    <strong>Throughput:</strong> Number of requests processed per second<br>
                    Different optimization strategies apply to each goal.</p>
                </div>
                <div class="technique-card">
                    <h5><i class="fas fa-balance-scale"></i> Performance Trade-offs</h5>
                    <p>Every optimization involves trade-offs: memory vs speed, code complexity vs performance, compile time vs runtime efficiency. Understanding these trade-offs is crucial.</p>
                </div>
            </div>
        </section>

        <section>
            <h2><i class="fas fa-brain"></i> Memory Management Optimization</h2>
            
            <div class="best-practice">
                <h3>1. Prefer Stack Allocation Over Heap</h3>
                <p>Stack allocation is significantly faster than heap allocation and automatically managed. The stack has better cache locality and eliminates allocation/deallocation overhead.</p>
                
                <div class="comparison-grid">
                    <div class="comparison-card bad-practice">
                        <h4><i class="fas fa-times"></i> Slow: Heap Allocation</h4>
                        <div class="code-example">
                            <pre><code class="language-cpp">// Slow - heap allocation
std::vector&lt;int&gt;* vec = new std::vector&lt;int&gt;(1000);
for (int i = 0; i &lt; 1000; ++i) {
    vec-&gt;push_back(i);
}
delete vec; // Manual cleanup required

// Even worse - repeated allocations
for (int i = 0; i &lt; 1000; ++i) {
    int* data = new int(i);
    process(data);
    delete data; // Thrashing the heap
}</code></pre>
                        </div>
                    </div>
                    
                    <div class="comparison-card good-practice">
                        <h4><i class="fas fa-check"></i> Fast: Stack Allocation</h4>
                        <div class="code-example">
                            <pre><code class="language-cpp">// Fast - stack allocation
std::vector&lt;int&gt; vec;
vec.reserve(1000); // Pre-allocate capacity
for (int i = 0; i &lt; 1000; ++i) {
    vec.push_back(i);
}
// Automatic cleanup

// Better - use stack for temporary data
for (int i = 0; i &lt; 1000; ++i) {
    int data = i;
    process(&data); // No allocation overhead
}</code></pre>
                        </div>
                    </div>
                </div>
                
                <div class="benchmark-result">
                    <strong>Performance Impact:</strong> Stack allocation is ~10-100x faster than heap allocation for small objects<br>
                    <strong>Memory Impact:</strong> Stack has better cache locality, leading to fewer cache misses
                </div>
            </div>

            <div class="best-practice">
                <h3>2. Smart Memory Management Techniques</h3>
                <p>When heap allocation is necessary, use smart pointers and modern C++ memory management techniques.</p>
                
                <div class="code-playground">
                    <div class="code-header">
                        <div class="code-title">
                            <i class="fas fa-brain"></i>
                            <span>Smart Pointer Optimization</span>
                        </div>
                        <div class="code-actions">
                            <button class="btn btn-primary">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                    </div>
                    <div class="code-example">
                        <pre><code class="language-cpp">// Smart pointer best practices
#include &lt;memory&gt;
#include &lt;vector&gt;

class PerformantClass {
public:
    // Use make_unique/make_shared for better performance
    static std::unique_ptr&lt;PerformantClass&gt; create() {
        return std::make_unique&lt;PerformantClass&gt;(); // Single allocation
    }
    
    static std::shared_ptr&lt;PerformantClass&gt; createShared() {
        return std::make_shared&lt;PerformantClass&gt;(); // Control block + object in one allocation
    }
};

// Container of smart pointers - prefer unique_ptr when possible
std::vector&lt;std::unique_ptr&lt;PerformantClass&gt;&gt; objects;
objects.reserve(1000); // Always reserve capacity

// Efficient object creation
for (int i = 0; i &lt; 1000; ++i) {
    objects.emplace_back(std::make_unique&lt;PerformantClass&gt;());
}

// Avoid shared_ptr unless sharing is actually needed
// shared_ptr has atomic reference counting overhead</code></pre>
                    </div>
                </div>
            </div>

            <div class="best-practice">
                <h3>3. Custom Memory Pools and Allocators</h3>
                <p>For performance-critical applications, custom allocators can provide significant speedups by reducing allocation overhead and improving cache locality.</p>
                
                <div class="code-example">
                    <pre><code class="language-cpp">// Advanced memory pool with alignment and type safety
#include &lt;cstdlib&gt;
#include &lt;new&gt;
#include &lt;type_traits&gt;

template&lt;typename T, size_t PoolSize = 1024 * 1024&gt;
class MemoryPool {
private:
    alignas(T) char pool[PoolSize];
    char* current;
    char* end;
    
public:
    MemoryPool() : current(pool), end(pool + PoolSize) {}
    
    template&lt;typename... Args&gt;
    T* construct(Args&&... args) {
        if (current + sizeof(T) &gt; end) {
            throw std::bad_alloc();
        }
        
        T* ptr = reinterpret_cast&lt;T*&gt;(current);
        current += sizeof(T);
        
        // Proper construction with perfect forwarding
        return new(ptr) T(std::forward&lt;Args&gt;(args)...);
    }
    
    void destroy(T* ptr) {
        if (ptr) {
            ptr-&gt;~T(); // Explicit destructor call
        }
    }
    
    void reset() { 
        current = pool; 
    }
    
    size_t capacity() const { 
        return PoolSize / sizeof(T); 
    }
    
    size_t available() const { 
        return (end - current) / sizeof(T); 
    }
};

// Stack-based allocator for STL containers
template&lt;typename T, size_t N&gt;
class StackAllocator {
private:
    alignas(T) char storage[N * sizeof(T)];
    size_t used = 0;
    
public:
    using value_type = T;
    
    T* allocate(size_t n) {
        if (used + n &gt; N) {
            throw std::bad_alloc();
        }
        T* result = reinterpret_cast&lt;T*&gt;(storage + used * sizeof(T));
        used += n;
        return result;
    }
    
    void deallocate(T* ptr, size_t n) {
        // Stack allocator doesn't actually deallocate
        // Memory is reclaimed when allocator is destroyed
    }
};

// Usage with STL containers
using FastVector = std::vector&lt;int, StackAllocator&lt;int, 1000&gt;&gt;;
FastVector vec; // Uses stack memory, very fast for small collections</code></pre>
                </div>
            </div>

            <div class="advanced-section">
                <h3><i class="fas fa-microscope"></i> Advanced Memory Techniques</h3>
                
                <div class="technique-grid">
                    <div class="technique-card">
                        <h5>Object Pooling</h5>
                        <div class="code-example">
                            <pre><code class="language-cpp">// Object pool for expensive-to-create objects
template&lt;typename T&gt;
class ObjectPool {
private:
    std::vector&lt;std::unique_ptr&lt;T&gt;&gt; pool;
    std::vector&lt;T*&gt; available;
    
public:
    T* acquire() {
        if (available.empty()) {
            return pool.emplace_back(
                std::make_unique&lt;T&gt;()
            ).get();
        }
        
        T* obj = available.back();
        available.pop_back();
        return obj;
    }
    
    void release(T* obj) {
        obj-&gt;reset(); // Reset object state
        available.push_back(obj);
    }
};</code></pre>
                        </div>
                    </div>
                    
                    <div class="technique-card">
                        <h5>Memory-Mapped Files</h5>
                        <div class="code-example">
                            <pre><code class="language-cpp">// Memory-mapped file for large data sets
#include &lt;sys/mman.h&gt;
#include &lt;fcntl.h&gt;

class MemoryMappedFile {
private:
    void* data;
    size_t size;
    
public:
    MemoryMappedFile(const char* filename) {
        int fd = open(filename, O_RDONLY);
        struct stat sb;
        fstat(fd, &sb);
        size = sb.st_size;
        
        data = mmap(nullptr, size, PROT_READ, 
                   MAP_PRIVATE, fd, 0);
        close(fd);
    }
    
    ~MemoryMappedFile() {
        munmap(data, size);
    }
    
    template&lt;typename T&gt;
    const T* get() const {
        return static_cast&lt;const T*&gt;(data);
    }
};</code></pre>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section>
            <h2><i class="fas fa-code"></i> Algorithm and Data Structure Optimization</h2>
            
            <div class="best-practice">
                <h3>3. Choose the Right Container</h3>
                <p>Different containers have vastly different performance characteristics. The choice of container can make orders of magnitude difference in performance.</p>
                
                <div class="code-playground">
                    <div class="code-header">
                        <div class="code-title">
                            <i class="fas fa-database"></i>
                            <span>Container Performance Comparison</span>
                        </div>
                        <div class="code-actions">
                            <button class="btn btn-primary">
                                <i class="fas fa-play"></i> Benchmark
                            </button>
                            <button class="btn btn-secondary">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                    </div>
                    <div class="code-example">
                        <pre><code class="language-cpp">// Comprehensive container performance guide
#include &lt;vector&gt;
#include &lt;list&gt;
#include &lt;deque&gt;
#include &lt;array&gt;
#include &lt;unordered_set&gt;
#include &lt;unordered_map&gt;
#include &lt;set&gt;
#include &lt;map&gt;

// Sequential containers performance characteristics
class ContainerBenchmark {
public:
    // std::vector - Cache-friendly, contiguous memory
    // Best for: Random access, iteration, when size is relatively stable
    // Complexity: O(1) access, O(1) amortized push_back, O(n) insertion
    void vectorExample() {
        std::vector&lt;int&gt; vec;
        vec.reserve(1000000); // Critical for performance!
        
        // Fastest iteration due to cache locality
        for (const auto& item : vec) {
            process(item); // Cache-friendly access
        }
    }
    
    // std::deque - Double-ended queue
    // Best for: Push/pop at both ends, when you need vector-like access
    // Complexity: O(1) access, O(1) push_front/back
    void dequeExample() {
        std::deque&lt;int&gt; deq;
        deq.push_front(1); // O(1)
        deq.push_back(2);  // O(1)
        // Slightly slower iteration than vector due to segmented storage
    }
    
    // std::list - Doubly-linked list
    // Best for: Frequent insertion/deletion in middle, splice operations
    // Complexity: O(1) insertion/deletion, O(n) access
    void listExample() {
        std::list&lt;int&gt; lst;
        auto it = lst.begin();
        lst.insert(it, 42); // O(1) insertion anywhere
        lst.erase(it);      // O(1) deletion
        // Poor cache performance for iteration
    }
    
    // std::array - Fixed-size array
    // Best for: When size is known at compile time
    // Complexity: O(1) access, zero overhead
    void arrayExample() {
        std::array&lt;int, 1000&gt; arr{}; // Stack allocated, no heap
        // Fastest possible container - zero overhead abstraction
        arr[500] = 42; // Direct memory access
    }
};

// Associative containers performance
class AssociativeContainers {
public:
    // std::unordered_map/set - Hash table
    // Best for: Fast lookups when order doesn't matter
    // Complexity: O(1) average, O(n) worst case
    void hashTableExample() {
        std::unordered_map&lt;std::string, int&gt; map;
        map.reserve(1000); // Pre-allocate buckets
        
        // Very fast lookup
        if (map.find("key") != map.end()) {
            // Found in O(1) average time
        }
    }
    
    // std::map/set - Red-black tree
    // Best for: When you need sorted order and logarithmic operations
    // Complexity: O(log n) for all operations
    void treeExample() {
        std::map&lt;int, std::string&gt; map;
        
        // Always sorted, predictable O(log n) performance
        auto it = map.lower_bound(42); // Efficient range queries
    }
};</code></pre>
                    </div>
                </div>
                
                <div class="performance-tip">
                    <h4><i class="fas fa-lightbulb"></i> Container Selection Guide</h4>
                    <div class="technique-grid">
                        <div class="technique-card">
                            <h5>High-Performance Scenarios</h5>
                            <ul>
                                <li><strong>Hot loops:</strong> std::array or std::vector</li>
                                <li><strong>Cache-sensitive:</strong> std::vector with reserve()</li>
                                <li><strong>Frequent lookups:</strong> std::unordered_map</li>
                                <li><strong>Small collections:</strong> std::array or small_vector</li>
                            </ul>
                        </div>
                        <div class="technique-card">
                            <h5>Memory-Efficient Scenarios</h5>
                            <ul>
                                <li><strong>Large objects:</strong> std::vector with move semantics</li>
                                <li><strong>Stable iterators:</strong> std::list or std::deque</li>
                                <li><strong>Sorted data:</strong> std::map or std::set</li>
                                <li><strong>Sparse data:</strong> std::unordered_map</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>

            <div class="best-practice">
                <h3>4. Advanced Loop Optimization Techniques</h3>
                <p>Loop optimization is crucial since loops are often the hottest parts of your code. Small improvements here can yield massive performance gains.</p>
                
                <div class="comparison-grid">
                    <div class="comparison-card bad-practice">
                        <h4><i class="fas fa-times"></i> Inefficient Loop Patterns</h4>
                        <div class="code-example">
                            <pre><code class="language-cpp">// Multiple performance issues
std::vector&lt;ComplexObject&gt; data = getData(); // Copy!
for (int i = 0; i &lt; data.size(); ++i) { // size() called every iteration
    if (data[i].getValue() % 2 == 0) { // Expensive division
        results.push_back( // May reallocate
            ExpensiveOperation().process(data[i]) // Temporary object
        );
    }
}

// Poor memory access pattern
for (int i = 0; i &lt; rows; ++i) {
    for (int j = 0; j &lt; cols; ++j) {
        matrix[j][i] = value; // Column-major access in row-major layout
    }
}</code></pre>
                        </div>
                    </div>
                    
                    <div class="comparison-card good-practice">
                        <h4><i class="fas fa-check"></i> Optimized Loop Patterns</h4>
                        <div class="code-example">
                            <pre><code class="language-cpp">// Highly optimized version
const auto& data = getData(); // Reference, no copy
results.reserve(data.size() / 2); // Pre-allocate based on estimation

// Cache-friendly iteration with range-based loop
for (const auto& item : data) {
    if ((item.getValue() & 1) == 0) { // Bit operation instead of modulo
        results.emplace_back( // Construct in-place
            ExpensiveOperation{}.process(item)
        );
    }
}

// Cache-friendly memory access pattern
for (int i = 0; i &lt; rows; ++i) {
    for (int j = 0; j &lt; cols; ++j) {
        matrix[i][j] = value; // Row-major access
    }
}</code></pre>
                        </div>
                    </div>
                </div>
            </div>

            <div class="advanced-section">
                <h3><i class="fas fa-chart-line"></i> Advanced Algorithm Optimization</h3>
                
                <div class="code-playground">
                    <div class="code-header">
                        <div class="code-title">
                            <i class="fas fa-rocket"></i>
                            <span>Loop Unrolling and Vectorization</span>
                        </div>
                    </div>
                    <div class="code-example">
                        <pre><code class="language-cpp">// Loop unrolling for better instruction-level parallelism
void optimizedSum(const std::vector&lt;float&gt;& data, float& result) {
    const size_t size = data.size();
    const size_t unroll_factor = 4;
    size_t i = 0;
    
    // Unrolled loop for better CPU pipeline utilization
    float sum1 = 0, sum2 = 0, sum3 = 0, sum4 = 0;
    for (; i + unroll_factor &lt;= size; i += unroll_factor) {
        sum1 += data[i];
        sum2 += data[i + 1];
        sum3 += data[i + 2];
        sum4 += data[i + 3];
    }
    
    // Handle remaining elements
    float remainder = 0;
    for (; i &lt; size; ++i) {
        remainder += data[i];
    }
    
    result = sum1 + sum2 + sum3 + sum4 + remainder;
}

// SIMD optimization using compiler intrinsics
#include &lt;immintrin.h&gt;

void simdSum(const float* data, size_t size, float& result) {
    const size_t simd_width = 8; // AVX2 processes 8 floats at once
    size_t i = 0;
    
    __m256 sum_vec = _mm256_setzero_ps();
    
    // Process 8 elements at a time
    for (; i + simd_width &lt;= size; i += simd_width) {
        __m256 data_vec = _mm256_load_ps(&data[i]);
        sum_vec = _mm256_add_ps(sum_vec, data_vec);
    }
    
    // Extract and sum the vector elements
    float sum_array[8];
    _mm256_store_ps(sum_array, sum_vec);
    
    float sum = 0;
    for (int j = 0; j &lt; 8; ++j) {
        sum += sum_array[j];
    }
    
    // Handle remaining elements
    for (; i &lt; size; ++i) {
        sum += data[i];
    }
    
    result = sum;
}</code></pre>
                    </div>
                </div>

                <div class="interactive-demo">
                    <h4><i class="fas fa-play-circle"></i> Performance Comparison Demo</h4>
                    <p>The SIMD version can be <strong>4-8x faster</strong> than the naive loop for large arrays, depending on the CPU architecture and compiler optimizations.</p>
                    
                    <div class="benchmark-result">
                        <strong>Benchmark Results (1M elements):</strong><br>
                        • Naive loop: 2.5ms<br>
                        • Unrolled loop: 1.8ms (28% faster)<br>
                        • SIMD version: 0.4ms (525% faster)<br>
                        • Compiler auto-vectorization: 0.6ms (316% faster)
                    </div>
                </div>
            </div>
        </section>

        <section>
            <h2><i class="fas fa-microchip"></i> Compiler Optimization Techniques</h2>
            
            <div class="best-practice">
                <h3>5. Use Move Semantics and Perfect Forwarding</h3>
                <p>Eliminate unnecessary copies by leveraging C++11+ move semantics.</p>
                
                <div class="code-example">
                    <pre><code class="language-cpp">class PerformantClass {
private:
    std::vector&lt;int&gt; data;
    std::string name;

public:
    // Move constructor
    PerformantClass(PerformantClass&amp;&amp; other) noexcept
        : data(std::move(other.data))
        , name(std::move(other.name)) {}
    
    // Move assignment
    PerformantClass&amp; operator=(PerformantClass&amp;&amp; other) noexcept {
        if (this != &other) {
            data = std::move(other.data);
            name = std::move(other.name);
        }
        return *this;
    }
    
    // Perfect forwarding constructor
    template&lt;typename T&gt;
    PerformantClass(T&amp;&amp; n) : name(std::forward&lt;T&gt;(n)) {}
    
    // Use emplace_back instead of push_back
    void addData(int value) {
        data.emplace_back(value); // Constructs in-place
    }
};

// Usage - no unnecessary copies
PerformantClass obj1(std::string("test"));
PerformantClass obj2 = std::move(obj1); // Move, don't copy</code></pre>
                </div>
            </div>

            <div class="best-practice">
                <h3>6. Enable Compiler Optimizations</h3>
                <p>Use appropriate compiler flags and help the compiler optimize your code.</p>
                
                <div class="code-example">
                    <pre><code class="language-bash"># Compilation flags for maximum performance
g++ -O3 -march=native -flto -DNDEBUG program.cpp

# Flag explanations:
# -O3: Maximum optimization level
# -march=native: Optimize for current CPU architecture
# -flto: Link-time optimization
# -DNDEBUG: Disable assertions in release builds</code></pre>
                </div>
                
                <div class="code-example">
                    <pre><code class="language-cpp">// Help the compiler with optimization hints
#include &lt;immintrin.h&gt;

// Likely/unlikely branch prediction hints (C++20)
if (condition) [[likely]] {
    // Most common path
    fastPath();
} else [[unlikely]] {
    // Rare path
    slowPath();
}

// Force inlining for critical functions
inline __attribute__((always_inline)) 
int criticalFunction(int x) {
    return x * x + 2 * x + 1;
}

// Restrict keyword for pointer optimization
void processArray(int* __restrict__ a, 
                 int* __restrict__ b, 
                 int size) {
    for (int i = 0; i &lt; size; ++i) {
        a[i] = b[i] * 2; // Compiler knows a and b don't overlap
    }
}</code></pre>
                </div>
            </div>
        </section>

        <section>
            <h2><i class="fas fa-tachometer-alt"></i> Cache Optimization</h2>
            
            <div class="best-practice">
                <h3>7. Optimize for Cache Locality</h3>
                <p>Design data structures and algorithms to be cache-friendly.</p>
                
                <div class="comparison-grid">
                    <div class="comparison-card bad-practice">
                        <h4><i class="fas fa-times"></i> Cache Unfriendly</h4>
                        <div class="code-example">
                            <pre><code class="language-cpp">// Bad: Poor cache locality
struct BadDesign {
    int id;
    char padding[60]; // Wastes cache line
    int value;
};

// Bad: Random memory access
for (int i = 0; i &lt; size; i += 7) {
    data[i] = processValue(data[i]);
}</code></pre>
                        </div>
                    </div>
                    
                    <div class="comparison-card good-practice">
                        <h4><i class="fas fa-check"></i> Cache Friendly</h4>
                        <div class="code-example">
                            <pre><code class="language-cpp">// Good: Compact data structure
struct GoodDesign {
    int id;
    int value;
}; // 8 bytes - fits multiple per cache line

// Good: Sequential access pattern
for (int i = 0; i &lt; size; ++i) {
    data[i] = processValue(data[i]);
}</code></pre>
                        </div>
                    </div>
                </div>
                
                <div class="performance-tip">
                    <h4><i class="fas fa-info-circle"></i> Cache Optimization Tips</h4>
                    <ul>
                        <li>Keep related data together in memory</li>
                        <li>Use struct-of-arrays instead of array-of-structs for bulk operations</li>
                        <li>Prefer sequential memory access patterns</li>
                        <li>Consider cache line size (typically 64 bytes) in data structure design</li>
                    </ul>
                </div>
            </div>
        </section>

        <section>
            <h2><i class="fas fa-chart-line"></i> Profiling and Measurement</h2>
            
            <div class="best-practice">
                <h3>8. Always Measure Performance</h3>
                <p>Use profiling tools and benchmarks to identify actual bottlenecks.</p>
                
                <div class="code-example">
                    <pre><code class="language-cpp">#include &lt;chrono&gt;
#include &lt;iostream&gt;

// Simple benchmark utility
class Timer {
private:
    std::chrono::high_resolution_clock::time_point start_time;
    
public:
    Timer() : start_time(std::chrono::high_resolution_clock::now()) {}
    
    ~Timer() {
        auto end_time = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;
                       (end_time - start_time);
        std::cout &lt;&lt; "Time: " &lt;&lt; duration.count() &lt;&lt; " microseconds\n";
    }
};

// Usage
void benchmarkFunction() {
    Timer timer; // Starts timing
    
    // Your code here
    expensiveOperation();
    
    // Timer destructor prints elapsed time
}

// Macro for easy benchmarking
#define BENCHMARK(code) \
    do { \
        Timer timer; \
        code; \
    } while(0)

// Example usage
BENCHMARK(
    std::sort(data.begin(), data.end());
);</code></pre>
                </div>
            </div>
        </section>

        <section class="quick-tips">
            <h2><i class="fas fa-rocket"></i> Quick Performance Tips</h2>
            <ul>
                <li><strong>Avoid premature optimization</strong> - Profile first, optimize second</li>
                <li><strong>Use const and constexpr</strong> - Help compiler optimize</li>
                <li><strong>Prefer algorithms</strong> - STL algorithms are highly optimized</li>
                <li><strong>Minimize dynamic allocations</strong> - Especially in hot loops</li>
                <li><strong>Use appropriate data types</strong> - Don't use double when float suffices</li>
                <li><strong>Enable compiler warnings</strong> - Use -Wall -Wextra to catch issues</li>
                <li><strong>Consider SIMD</strong> - For numerical computations</li>
                <li><strong>Avoid virtual functions</strong> - In performance-critical code</li>
                <li><strong>Use string_view</strong> - Instead of const string& when possible</li>
                <li><strong>Consider parallel algorithms</strong> - C++17 execution policies</li>
                <li><strong>Profile memory usage</strong> - Use tools like Valgrind</li>
                <li><strong>Optimize I/O operations</strong> - Buffer reads/writes appropriately</li>
            </ul>
        </section>

        <section>
            <h2><i class="fas fa-flag-checkered"></i> Conclusion: The Performance Optimization Mindset</h2>
            <p>Writing performance-optimized C++ code is both an art and a science that requires a deep understanding of hardware, algorithms, and language features. The key principles for achieving maximum performance are:</p>
            
            <div class="technique-grid">
                <div class="technique-card">
                    <h5><i class="fas fa-search"></i> 1. Measure First</h5>
                    <p>Use profilers to identify real bottlenecks. Performance intuition is often wrong, and optimizing the wrong code is wasted effort.</p>
                </div>
                <div class="technique-card">
                    <h5><i class="fas fa-brain"></i> 2. Algorithm Trumps Micro-optimizations</h5>
                    <p>A better algorithm (O(n log n) vs O(n²)) will always beat micro-optimizations. Focus on algorithmic improvements first.</p>
                </div>
                <div class="technique-card">
                    <h5><i class="fas fa-memory"></i> 3. Memory is the New Bottleneck</h5>
                    <p>Modern CPUs are incredibly fast, but memory access is relatively slow. Design for cache locality and minimize memory allocations.</p>
                </div>
                <div class="technique-card">
                    <h5><i class="fas fa-tools"></i> 4. Leverage Compiler Intelligence</h5>
                    <p>Modern compilers are extremely sophisticated. Use optimization flags, provide hints, and write code that's easy for the compiler to optimize.</p>
                </div>
            </div>
            
            <div class="advanced-section">
                <h3><i class="fas fa-chart-line"></i> Performance Optimization Roadmap</h3>
                <ol style="font-size: 1.1em; line-height: 1.8;">
                    <li><strong>Profile and Identify Hotspots</strong> - Use tools like perf, VTune, or profilers to find the actual bottlenecks</li>
                    <li><strong>Optimize Algorithms</strong> - Choose better data structures and algorithms before micro-optimizations</li>
                    <li><strong>Memory Optimization</strong> - Minimize allocations, improve cache locality, use appropriate containers</li>
                    <li><strong>Compiler Optimization</strong> - Use optimization flags, enable LTO, consider PGO</li>
                    <li><strong>Parallel Processing</strong> - Leverage multiple cores with parallel algorithms and threading</li>
                    <li><strong>Hardware-Specific Optimization</strong> - Use SIMD instructions, optimize for target architecture</li>
                    <li><strong>Validate and Iterate</strong> - Always measure the impact of optimizations and iterate</li>
                </ol>
            </div>
            
            <div class="performance-tip">
                <h4><i class="fas fa-quote-left"></i> Final Thoughts</h4>
                <p><em>"Premature optimization is the root of all evil, but when performance matters, understanding these techniques can make your C++ code absolutely fly! Remember: <strong>measure, optimize, validate, repeat</strong>."</em></p>
                
                <div style="margin-top: 20px; padding: 15px; background: rgba(255, 255, 255, 0.8); border-radius: 8px;">
                    <strong>Key Takeaway:</strong> Performance optimization is an iterative process. Start with clean, readable code, identify bottlenecks through profiling, apply appropriate optimizations, and always validate that your changes actually improve performance. The techniques in this guide can help you achieve significant performance improvements when applied judiciously to the right parts of your codebase.
                </div>
            </div>
        </section>

        <section>
            <h2><i class="fas fa-magic"></i> Modern C++ Performance Features</h2>
            
            <div class="advanced-section">
                <h3><i class="fas fa-forward"></i> C++17/20/23 Performance Features</h3>
                
                <div class="technique-grid">
                    <div class="technique-card">
                        <h5>Parallel Algorithms (C++17)</h5>
                        <div class="code-example">
                            <pre><code class="language-cpp">#include &lt;execution&gt;
#include &lt;algorithm&gt;
#include &lt;numeric&gt;

// Parallel STL algorithms
std::vector&lt;int&gt; data(1000000);

// Parallel sort - automatically uses multiple threads
std::sort(std::execution::par_unseq, 
          data.begin(), data.end());

// Parallel transform
std::transform(std::execution::par,
               data.begin(), data.end(),
               data.begin(),
               [](int x) { return x * x; });

// Parallel reduce
auto sum = std::reduce(std::execution::par,
                      data.begin(), data.end(),
                      0);

// Custom parallel algorithm
template&lt;typename Iterator, typename Func&gt;
void parallel_for_each(Iterator first, Iterator last, Func f) {
    const auto length = std::distance(first, last);
    const auto num_threads = std::thread::hardware_concurrency();
    const auto chunk_size = length / num_threads;
    
    std::vector&lt;std::future&lt;void&gt;&gt; futures;
    
    for (size_t i = 0; i &lt; num_threads; ++i) {
        auto chunk_start = first + i * chunk_size;
        auto chunk_end = (i == num_threads - 1) ? last : chunk_start + chunk_size;
        
        futures.emplace_back(
            std::async(std::launch::async, [=]() {
                std::for_each(chunk_start, chunk_end, f);
            })
        );
    }
    
    for (auto& future : futures) {
        future.wait();
    }
}</code></pre>
                        </div>
                    </div>
                    
                    <div class="technique-card">
                        <h5>Structured Bindings &amp; Optimization</h5>
                        <div class="code-example">
                            <pre><code class="language-cpp">// C++17 structured bindings for cleaner, faster code
#include &lt;tuple&gt;
#include &lt;unordered_map&gt;

// Efficient map iteration
std::unordered_map&lt;std::string, int&gt; map;

// Old way - potential extra copies
for (const auto& pair : map) {
    const std::string& key = pair.first;
    int value = pair.second;
}

// C++17 way - more efficient, clearer
for (const auto& [key, value] : map) {
    // Direct access, no pair intermediate
    process(key, value);
}

// Function returning multiple values efficiently
std::tuple&lt;bool, size_t, double&gt; processData() {
    return {true, 42, 3.14};
}

// Clean unpacking
auto [success, count, result] = processData();

// Perfect for performance-critical parsing
struct ParseResult {
    bool valid;
    size_t bytes_consumed;
    int value;
};

ParseResult parseInteger(const char* input) {
    // Implementation...
    return {true, 4, 1234};
}

// Usage
if (auto [valid, consumed, value] = parseInteger(buffer); valid) {
    buffer += consumed;
    // Use value...
}</code></pre>
                        </div>
                    </div>
                </div>
            </div>

            <div class="best-practice">
                <h3>C++20 Concepts and Constraints</h3>
                <p>Concepts enable better optimization by providing the compiler with more information about type requirements.</p>
                
                <div class="code-example">
                    <pre><code class="language-cpp">// C++20 concepts for better optimization
#include &lt;concepts&gt;
#include &lt;type_traits&gt;

// Define performance-oriented concepts
template&lt;typename T&gt;
concept Trivial = std::is_trivial_v&lt;T&gt;;

template&lt;typename T&gt;
concept Arithmetic = std::is_arithmetic_v&lt;T&gt;;

template&lt;typename Container&gt;
concept ContiguousContainer = requires(Container c) {
    c.data();
    c.size();
    { c.begin() } -&gt; std::contiguous_iterator;
};

// Optimized algorithms using concepts
template&lt;Arithmetic T&gt;
constexpr T fastMultiply(T a, T b) noexcept {
    if constexpr (std::is_integral_v&lt;T&gt;) {
        // Compiler can optimize integer multiplication better
        return a * b;
    } else {
        // Different strategy for floating point
        return a * b;
    }
}

// Container-aware optimizations
template&lt;ContiguousContainer Container&gt;
void optimizedProcess(const Container& container) {
    // Compiler knows memory is contiguous
    // Can generate vectorized code more easily
    const auto* data = container.data();
    const auto size = container.size();
    
    // SIMD-friendly loop
    for (size_t i = 0; i &lt; size; ++i) {
        process(data[i]);
    }
}

// Constraint-based function selection
template&lt;typename T&gt;
void sort_impl(std::vector&lt;T&gt;& vec) requires Trivial&lt;T&gt; {
    // Use radix sort for trivial types
    radix_sort(vec.begin(), vec.end());
}

template&lt;typename T&gt;
void sort_impl(std::vector&lt;T&gt;& vec) requires (!Trivial&lt;T&gt;) {
    // Use comparison sort for complex types
    std::sort(vec.begin(), vec.end());
}</code></pre>
                </div>
            </div>
        </section>

        <section>
            <h2><i class="fas fa-tools"></i> Advanced Profiling and Optimization Tools</h2>
            
            <div class="best-practice">
                <h3>9. Comprehensive Performance Analysis</h3>
                <p>Modern C++ development requires sophisticated profiling tools to identify performance bottlenecks accurately.</p>
                
                <div class="code-playground">
                    <div class="code-header">
                        <div class="code-title">
                            <i class="fas fa-chart-line"></i>
                            <span>Advanced Benchmarking Framework</span>
                        </div>
                        <div class="code-actions">
                            <button class="btn btn-primary">
                                <i class="fas fa-play"></i> Run Benchmark
                            </button>
                        </div>
                    </div>
                    <div class="code-example">
                        <pre><code class="language-cpp">// Professional benchmarking with statistical analysis
#include &lt;chrono&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;
#include &lt;numeric&gt;
#include &lt;cmath&gt;

class AdvancedBenchmark {
private:
    std::vector&lt;double&gt; measurements;
    
public:
    template&lt;typename Func&gt;
    void benchmark(const std::string& name, Func&& func, int iterations = 1000) {
        measurements.clear();
        measurements.reserve(iterations);
        
        // Warm-up phase
        for (int i = 0; i &lt; 10; ++i) {
            func();
        }
        
        // Actual measurements
        for (int i = 0; i &lt; iterations; ++i) {
            auto start = std::chrono::high_resolution_clock::now();
            func();
            auto end = std::chrono::high_resolution_clock::now();
            
            auto duration = std::chrono::duration_cast&lt;std::chrono::nanoseconds&gt;(end - start);
            measurements.push_back(duration.count());
        }
        
        reportStatistics(name);
    }
    
private:
    void reportStatistics(const std::string& name) {
        std::sort(measurements.begin(), measurements.end());
        
        double mean = std::accumulate(measurements.begin(), measurements.end(), 0.0) / measurements.size();
        double median = measurements[measurements.size() / 2];
        double min_val = measurements.front();
        double max_val = measurements.back();
        
        // Calculate standard deviation
        double variance = std::accumulate(measurements.begin(), measurements.end(), 0.0,
            [mean](double acc, double val) {
                return acc + std::pow(val - mean, 2);
            }) / measurements.size();
        double stddev = std::sqrt(variance);
        
        // Percentiles
        double p95 = measurements[static_cast&lt;size_t&gt;(measurements.size() * 0.95)];
        double p99 = measurements[static_cast&lt;size_t&gt;(measurements.size() * 0.99)];
        
        std::cout &lt;&lt; "=== " &lt;&lt; name &lt;&lt; " ===" &lt;&lt; std::endl;
        std::cout &lt;&lt; "Mean: " &lt;&lt; mean &lt;&lt; " ns" &lt;&lt; std::endl;
        std::cout &lt;&lt; "Median: " &lt;&lt; median &lt;&lt; " ns" &lt;&lt; std::endl;
        std::cout &lt;&lt; "Min: " &lt;&lt; min_val &lt;&lt; " ns" &lt;&lt; std::endl;
        std::cout &lt;&lt; "Max: " &lt;&lt; max_val &lt;&lt; " ns" &lt;&lt; std::endl;
        std::cout &lt;&lt; "Std Dev: " &lt;&lt; stddev &lt;&lt; " ns" &lt;&lt; std::endl;
        std::cout &lt;&lt; "95th percentile: " &lt;&lt; p95 &lt;&lt; " ns" &lt;&lt; std::endl;
        std::cout &lt;&lt; "99th percentile: " &lt;&lt; p99 &lt;&lt; " ns" &lt;&lt; std::endl;
    }
};

// CPU performance counters (Linux example)
#include &lt;linux/perf_event.h&gt;
#include &lt;syscall.h&gt;
#include &lt;unistd.h&gt;

class PerfCounters {
private:
    int cache_misses_fd = -1;
    int instructions_fd = -1;
    
public:
    PerfCounters() {
        // Setup cache miss counter
        struct perf_event_attr cache_attr = {};
        cache_attr.type = PERF_TYPE_HARDWARE;
        cache_attr.config = PERF_COUNT_HW_CACHE_MISSES;
        cache_attr.size = sizeof(cache_attr);
        cache_attr.disabled = 1;
        
        cache_misses_fd = syscall(__NR_perf_event_open, &cache_attr, 0, -1, -1, 0);
        
        // Setup instruction counter
        struct perf_event_attr inst_attr = {};
        inst_attr.type = PERF_TYPE_HARDWARE;
        inst_attr.config = PERF_COUNT_HW_INSTRUCTIONS;
        inst_attr.size = sizeof(inst_attr);
        inst_attr.disabled = 1;
        
        instructions_fd = syscall(__NR_perf_event_open, &inst_attr, 0, -1, -1, 0);
    }
    
    void start() {
        ioctl(cache_misses_fd, PERF_EVENT_IOC_RESET, 0);
        ioctl(instructions_fd, PERF_EVENT_IOC_RESET, 0);
        ioctl(cache_misses_fd, PERF_EVENT_IOC_ENABLE, 0);
        ioctl(instructions_fd, PERF_EVENT_IOC_ENABLE, 0);
    }
    
    void stop() {
        ioctl(cache_misses_fd, PERF_EVENT_IOC_DISABLE, 0);
        ioctl(instructions_fd, PERF_EVENT_IOC_DISABLE, 0);
        
        long long cache_misses, instructions;
        read(cache_misses_fd, &cache_misses, sizeof(cache_misses));
        read(instructions_fd, &instructions, sizeof(instructions));
        
        std::cout &lt;&lt; "Cache misses: " &lt;&lt; cache_misses &lt;&lt; std::endl;
        std::cout &lt;&lt; "Instructions: " &lt;&lt; instructions &lt;&lt; std::endl;
        std::cout &lt;&lt; "Cache miss rate: " &lt;&lt; (double)cache_misses / instructions * 100 &lt;&lt; "%" &lt;&lt; std::endl;
    }
    
    ~PerfCounters() {
        if (cache_misses_fd != -1) close(cache_misses_fd);
        if (instructions_fd != -1) close(instructions_fd);
    }
};</code></pre>
                    </div>
                </div>
            </div>

            <div class="interactive-demo">
                <h4><i class="fas fa-microscope"></i> Popular Profiling Tools</h4>
                <div class="technique-grid">
                    <div class="technique-card">
                        <h5>Intel VTune Profiler</h5>
                        <p>Comprehensive CPU and GPU profiling with microarchitecture analysis</p>
                        <div class="code-example">
                            <pre><code class="language-bash"># Profile with VTune
vtune -collect hotspots -app-args ./my_program
vtune -collect memory-access -app-args ./my_program</code></pre>
                        </div>
                    </div>
                    <div class="technique-card">
                        <h5>Perf (Linux)</h5>
                        <p>Low-overhead statistical profiler with hardware counter support</p>
                        <div class="code-example">
                            <pre><code class="language-bash"># Basic profiling
perf record -g ./my_program
perf report

# Cache analysis
perf stat -e cache-misses,cache-references ./my_program</code></pre>
                        </div>
                    </div>
                    <div class="technique-card">
                        <h5>Google Benchmark</h5>
                        <p>Industry-standard microbenchmarking library</p>
                        <div class="code-example">
                            <pre><code class="language-cpp">#include &lt;benchmark/benchmark.h&gt;

static void BM_StringCreation(benchmark::State& state) {
  for (auto _ : state)
    std::string empty_string;
}
BENCHMARK(BM_StringCreation);

BENCHMARK_MAIN();</code></pre>
                        </div>
                    </div>
                    <div class="technique-card">
                        <h5>Valgrind Callgrind</h5>
                        <p>Detailed call-graph profiling and cache simulation</p>
                        <div class="code-example">
                            <pre><code class="language-bash"># Profile with Callgrind
valgrind --tool=callgrind ./my_program
kcachegrind callgrind.out.*</code></pre>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="quick-tips">
            <h2><i class="fas fa-rocket"></i> Expert Performance Tips &amp; Best Practices</h2>
            <div class="technique-grid">
                <div class="technique-card">
                    <h5>Compiler Optimization</h5>
                    <ul>
                        <li><strong>Use profile-guided optimization (PGO)</strong> for 10-15% performance gains</li>
                        <li><strong>Enable link-time optimization (LTO)</strong> for cross-module optimization</li>
                        <li><strong>Use __builtin_expect</strong> for branch prediction hints</li>
                        <li><strong>Mark functions as noexcept</strong> for better optimization</li>
                    </ul>
                </div>
                <div class="technique-card">
                    <h5>Memory Optimization</h5>
                    <ul>
                        <li><strong>Minimize dynamic allocations</strong> in hot paths</li>
                        <li><strong>Use object pools</strong> for frequently created/destroyed objects</li>
                        <li><strong>Align data structures</strong> to cache line boundaries</li>
                        <li><strong>Consider memory-mapped files</strong> for large datasets</li>
                    </ul>
                </div>
                <div class="technique-card">
                    <h5>Algorithm Optimization</h5>
                    <ul>
                        <li><strong>Choose O(1) algorithms</strong> over O(log n) when possible</li>
                        <li><strong>Use branch-free algorithms</strong> for predictable performance</li>
                        <li><strong>Implement early termination</strong> in search algorithms</li>
                        <li><strong>Consider parallel algorithms</strong> for CPU-intensive tasks</li>
                    </ul>
                </div>
                <div class="technique-card">
                    <h5>Modern C++ Features</h5>
                    <ul>
                        <li><strong>Use constexpr for compile-time computation</strong></li>
                        <li><strong>Leverage move semantics</strong> to eliminate copies</li>
                        <li><strong>Use structured bindings</strong> for cleaner, faster code</li>
                        <li><strong>Employ concepts</strong> for better optimization opportunities</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
</body>
</html>
